{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17762bec-b134-4ad5-abbf-8e67b9a9f403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 23:41:41 WARN Utils: Your hostname, gabriel-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "25/04/21 23:41:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/gabriel/Documents/GitHub/eg-dados-apache-spark/.venv/lib/python3.13/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/gabriel/.ivy2/cache\n",
      "The jars for the packages stored in: /home/gabriel/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-51d59057-c7de-4382-a01b-f3713d773d2e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.6.1 in central\n",
      ":: resolution report :: resolve 368ms :: artifacts dl 10ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.6.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-51d59057-c7de-4382-a01b-f3713d773d2e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/10ms)\n",
      "25/04/21 23:41:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Inicializa uma sessão do Spark com as configurações do Iceberg\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "  .appName(\"IcebergLocalDevelopment\") \\\n",
    "  .config(\"spark.driver.host\", \"localhost\") \\\n",
    "  .config('spark.jars.packages', 'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1') \\\n",
    "  .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "  .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "  .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "  .config(\"spark.sql.catalog.local.warehouse\", \"spark-warehouse/iceberg\") \\\n",
    "  .config(\"spark.sql.catalog.local.create-namespace\", \"true\") \\\n",
    "  .config(\"spark.driver.bindAddress\", \"localhost\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172d5426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criação da tabela\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS local.iceberg.covid_daily_vaccinations (\n",
    "        date DATE,\n",
    "        location STRING,\n",
    "        daily_vaccinations DOUBLE,\n",
    "        people_fully_vaccinated DOUBLE\n",
    "    ) USING iceberg PARTITIONED BY (year(date));\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb76965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------------------+-----------------------+\n",
      "|      date|location|daily_vaccinations|people_fully_vaccinated|\n",
      "+----------+--------+------------------+-----------------------+\n",
      "|2024-01-01|   Aruba|               0.0|                   NULL|\n",
      "|2024-01-02|   Aruba|               0.0|                   NULL|\n",
      "|2024-01-03|   Aruba|               0.0|                   NULL|\n",
      "|2024-01-04|   Aruba|               0.0|                   NULL|\n",
      "|2024-01-05|   Aruba|               0.0|                   NULL|\n",
      "|2024-01-06|   Aruba|               0.0|                   NULL|\n",
      "|2024-01-07|   Aruba|               0.0|                   NULL|\n",
      "|2024-01-08|   Aruba|               0.0|                84364.0|\n",
      "|2024-01-09|   Aruba|               0.0|                   NULL|\n",
      "|2024-01-10|   Aruba|               0.0|                84364.0|\n",
      "|2024-01-11|   Aruba|               1.0|                   NULL|\n",
      "|2024-01-12|   Aruba|               1.0|                84365.0|\n",
      "|2024-01-13|   Aruba|               1.0|                   NULL|\n",
      "|2024-01-14|   Aruba|               1.0|                   NULL|\n",
      "|2024-01-15|   Aruba|               1.0|                   NULL|\n",
      "|2024-01-16|   Aruba|               1.0|                   NULL|\n",
      "|2024-01-17|   Aruba|               1.0|                   NULL|\n",
      "|2024-01-18|   Aruba|               1.0|                   NULL|\n",
      "|2024-01-19|   Aruba|               0.0|                84366.0|\n",
      "|2024-01-20|   Aruba|               0.0|                   NULL|\n",
      "+----------+--------+------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM local.iceberg.covid_daily_vaccinations\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92201e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "df = spark.read.csv(\"data/covid-19/vaccinations.csv\", header=True)\n",
    "\n",
    "df = df.withColumn(\"date\", to_date(df[\"date\"], \"yyyy-MM-dd\"))\n",
    "df = df.withColumn(\"daily_vaccinations\", col(\"daily_vaccinations\").cast(\"double\"))\n",
    "df = df.withColumn(\"people_fully_vaccinated\", col(\"people_fully_vaccinated\").cast(\"double\"))\n",
    "\n",
    "df.writeTo(\"local.iceberg.covid_daily_vaccinations\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55dbbc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    INSERT INTO local.iceberg.covid_daily_vaccinations\n",
    "    VALUES\n",
    "        (DATE('2025-04-21'), 'Brazil', 20000.0, 15000000.0),\n",
    "        (DATE('2025-04-20'), 'USA', 30000.0, 25000000.0),\n",
    "        (DATE('2025-04-19'), 'India', 40000.0, 35000000.0)\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14a66d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\" \n",
    "    UPDATE local.iceberg.covid_daily_vaccinations\n",
    "    SET daily_vaccinations = 50000.0\n",
    "    WHERE location = 'Brazil'\n",
    "    AND date = DATE('2025-04-21')\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48c9ae2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------------------+-----------------------+\n",
      "|      date|location|daily_vaccinations|people_fully_vaccinated|\n",
      "+----------+--------+------------------+-----------------------+\n",
      "|2025-04-21|  Brazil|           50000.0|                  1.5E7|\n",
      "+----------+--------+------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM local.iceberg.covid_daily_vaccinations \n",
    "    WHERE location = 'Brazil' AND date = DATE('2025-04-21')\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ac98539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    DELETE FROM local.iceberg.covid_daily_vaccinations\n",
    "    WHERE location = 'Brazil' AND date = DATE('2025-04-21')\n",
    "    \"\"\"\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
